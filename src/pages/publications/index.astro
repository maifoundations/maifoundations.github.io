---
import { Comment } from 'astro-pure/advanced'
import { Button, Collapse, Spoiler, Timeline } from 'astro-pure/user'
import PageLayout from '@/layouts/CommonPage.astro'
import Substats from '@/components/about/Substats.astro'
import ToolSection from '@/components/about/ToolSection.astro'

const headings = [
  { depth: 2, slug: '2025', text: '2025' },
]
---

<PageLayout title='Publications' {headings} info='/publications'>
  <h2 id='2025'>2025</h2>

  <p>
    <b>Learning to Think Fast and Slow for Visual Language Models</b> <br>
    Chenyu Lin, Cheng Chi, Jinlin Wu, Sharon Li, Kaiyang Zhou <br>
    <i>arXiv</i> <br>
    <a href='https://arxiv.org/pdf/2511.16670' target='_blank'>pdf</a> |
    <a href='https://github.com/maifoundations/DualMindVLM' target='_blank'>code</a>
  </p>

  <p>
    <b>Mitigating Hallucination in Multimodal LLMs with Layer Contrastive Decoding</b> <br>
    Bingkui Tong, Jiaer Xia, Kaiyang Zhou <br>
    <i>NeurIPS 2025 Workshop on Multimodal Algorithmic Reasoning</i> <br>
    <a href='https://www.arxiv.org/pdf/2509.25177' target='_blank'>pdf</a> |
    <a href='https://github.com/maifoundations/LayerCD' target='_blank'>code</a>
  </p>

  <p>
    <b>Measuring Epistemic Humility in Multimodal Large Language Models</b> <br>
    Bingkui Tong, Jiaer Xia, Sifeng Shang, Kaiyang Zhou <br>
    <i>arXiv</i> <br>
    <a href='https://arxiv.org/pdf/2509.09658' target='_blank'>pdf</a> |
    <a href='https://github.com/maifoundations/HumbleBench' target='_blank'>code</a> |
    <a href='https://huggingface.co/datasets/maifoundations/HumbleBench' target='_blank'>dataset</a> |
    <a href="/blog/humblebench">blog</a>
  </p>

  <p>
    <b>Bootstrapping Grounded Chain-of-Thought in Multimodal LLMs for Data-Efficient Model Adaptation</b> <br>
    Jiaer Xia, Bingkui Tong, Yuhang Zang, Rui Shao, Kaiyang Zhou <br>
    <i>International Conference on Computer Vision (ICCV), 2025</i> <span class="text-highlight">(Highlight)</span> <br>
    <a href='https://arxiv.org/pdf/2507.02859' target='_blank'>pdf</a> |
    <a href='https://github.com/maifoundations/GCoT' target='_blank'>code</a> |
    <a href="/blog/gcot">blog</a>
  </p>

  <p>
    <b>Training-Free Watermarking for Autoregressive Image Generation</b> <br>
    Yu Tong, Zihao Pan, Shuai Yang, Kaiyang Zhou <br>
    <i>arXiv</i> <br>
    <a href='https://arxiv.org/pdf/2505.14673' target='_blank'>pdf</a> |
    <a href='https://github.com/maifoundations/IndexMark' target='_blank'>code</a> |
    <a href="/blog/indexmark">blog</a>
  </p>
  
  <p>
    <b>Visionary-R1: Mitigating Shortcuts in Visual Reasoning with Reinforcement Learning</b> <br>
    Jiaer Xia, Yuhang Zang, Peng Gao, Sharon Li, Kaiyang Zhou <br>
    <i>arXiv</i> <br>
    <a href='https://arxiv.org/pdf/2505.14677' target='_blank'>pdf</a> |
    <a href='https://github.com/maifoundations/Visionary-R1' target='_blank'>code</a> |
    <a href="https://huggingface.co/maifoundations/Visionary-R1">model</a> |
    <a href="/blog/visionary-r1">blog</a>
  </p>
  
  <p>
    <b>Fine-tuning Quantized Neural Networks with Zeroth-order Optimization</b> <br>
    Sifeng Shang, Jiayi Zhou, Chenyu Lin, Minxian Li, Kaiyang Zhou <br>
    <i>arXiv</i> <br>
    <a href='https://arxiv.org/pdf/2505.13430' target='_blank'>pdf</a> |
    <a href='https://github.com/maifoundations/QZO' target='_blank'>code</a> |
    <a href="/blog/qzo">blog</a>
  </p>
</PageLayout>
